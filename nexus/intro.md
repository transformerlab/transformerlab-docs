---
title: Super Duper Team Edition
slug: .
sidebar_position: 1
---

# Transformer Lab Super-Duper Team Edition

:::note

These documents for our team edition are currently hidden until our launch. Please bookmark them to return to them again.

:::

## Introduction

Transformer Lab is designed to support the needs of ML researchers working on a team.

## Video

The following video (coming soon) demonstrates what is possible with Transformer Lab Super-Duper Team Edition.

## With Transformer Lab Super-Duper Team Edition you can:

- **Scale Effortlessly:** Researchers can go from quick Jupyter notebooks to production ML runs across hundreds or thousands of GPUs more easily than ever.
- **No More Orchestration:** You donâ€™t need to worry about GPU orchestration. Simply request resources and supply a script; the system handles all networking and provisioning.
- **Use Your Own Stack:** Write code using the tools you are familiar with. Transformer Lab imposes few restrictions and works with common libraries like PyTorch, TensorFlow, Ray, MLFlow, Weights and Biases, Hugging Face, and Unsloth.
- **Run Any Workload:** From LLMs, vision, and audio models to traditional workloads like XGBoost and YOLO, we support it all. We also support broad compute types, including NVIDIA, AMD, TPU, and Apple Silicon/MLX.
- **Complexity Made Simple:** Capabilities that used to require complex engineering are now built-in.
    - This includes capturing checkpoints (with auto-restart)
    - one-line to add hyperparameter sweeps
    - storing artifacts in a global object store accessible even after ephemeral nodes terminate.

Ultimately, all results are automatically tracked, visualized, and sharable, so you never have to think about the logistics of your data.